pip install pandas as pd
pip install numpy as np
pip install matplotlib
pip install beautifulsoup4
pip install sklearn
pip install pandas_datareader
pip install mpl_finance

import datetime as dt
import matplotlib.pyplot as plt
from matplotlib import style
import mpl_finance
from mpl_finance import candlestick_ohlc
import matplotlib.dates as mdates
import pandas_datareader.data as web

style.use('ggplot')

# specifies a range of time to pull data from
start = dt.datetime(2000,1,1)
end = dt.datetime(2019,12,31)

# specifies ticker and data source
df = web.DataReader('TSLA', 'yahoo', start, end)

"""df['Adj Close'].plot()
plt.show() # if not using an interactive version of Python"""

# creates a new column that lists moving average
"""df['100ma'] = df['Adj Close'].rolling(window=100, min_periods=0).mean()
df.dropna(inplace=True)"""

# resamples data to 10 days
df_ohlc = df['Adj Close'].resample('10D').ohlc()
df_volume = df['Volume'].resample('10D').sum()

# resets index of ohlc so that 'Date' is a column
df_ohlc.reset_index(inplace=True)

# converts date time object to mdate number
df_ohlc['Date'] = df_ohlc['Date'].map(mdates.date2num)

ax1 = plt.subplot2grid((6,1), (0,0), rowspan=5, colspan=1)
ax2 = plt.subplot2grid((6,1), (5,0), rowspan=1, colspan=1, sharex=ax1)
ax1.xaxis_date()

candlestick_ohlc(ax1, df_ohlc.values, width=2, colorup='g')
ax2.fill_between(df_volume.index.map(mdates.date2num), df_volume.values, 0)

import pickle # serializes any Python object
import requests
import bs4 as bs
import datetime as dt
import os 
import pandas as pd
import numpy as np

def save_sp500_tickers():
    resp = requests.get('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')
    soup = bs.BeautifulSoup(resp.text, 'lxml')
    table = soup.find('table', {'class': 'wikitable sortable'})
    tickers = []
    for row in table.findAll('tr')[1:]:
        ticker = row.findAll('td')[0].text
        ticker = ticker[:-1]
        mapping = str.maketrans(".","-")
        ticker = ticker.translate(mapping)
        tickers.append(ticker)
    with open('sp500tickers.pickle','wb') as f:
        pickle.dump(tickers, f)
    return tickers
# save_sp500_tickers()

def get_data_from_yahoo(reload_sp500=False):
    if reload_sp500:
        tickers = save_sp500_tickers()
    else:
        with open("sp500tickers.pickle", "rb") as f:
            tickers = pickle.load(f)
    if not os.path.exists('stock_dfs'):
        os.makedirs('stock_dfs')
    start = dt.datetime(2019, 6, 8)
    end = dt.datetime.now()
    for ticker in tickers:
        print(ticker)
        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):
            df = web.DataReader(ticker, 'yahoo', start, end)
            df.reset_index(inplace=True)
            df.set_index("Date", inplace=True)
            df.to_csv('stock_dfs/{}.csv'.format(ticker))
        else:
            print('Already have {}'.format(ticker))
#get_data_from_yahoo()

def compile_data():
    with open('sp500tickers.pickle','rb') as f:
        tickers = pickle.load(f)
    main_df = pd.DataFrame()
    
    for count,ticker in enumerate(tickers):
        df = pd.read_csv('stock_dfs/{}.csv'.format(ticker))
        df.set_index('Date', inplace=True)

        df.rename(columns = {'Adj Close':ticker}, inplace=True)
        df.drop(['Open','High','Low','Close','Volume'], 1, inplace=True)

        if main_df.empty:
            main_df = df
        else:
            main_df = main_df.join(df, how='outer')

        if count % 10 == 0:
            print(count)
        
    print(main_df.head())
    main_df.to_csv('sp500_joined_closes.csv')

compile_data()

"""S&P 500 Companies Correlation Table"""

def visualize_data():
    df_corr = df.corr()
    # print(df_corr.head())
    
    data = df_corr.values # an array of columns and rows
    fig = plt.figure()
    ax = fig.add_subplot(1,1,1)
    
    heatmap = ax.pcolor(data, cmap=plt.cm.RdYlGn)
    fig.colorbar(heatmap)
    ax.set_xticks(np.arange(data.shape[0]) + 0.5, minor=False)
    ax.set_yticks(np.arange(data.shape[1]) + 0.5, minor=False)
    ax.invert_yaxis()
    ax.xaxis.tick_top()
    
    column_labels = df_corr.columns
    row_labels = df_corr.index
    
    ax.set_xticklabels(column_labels)
    ax.set_yticklabels(row_labels)
    plt.xticks(rotation=90)
    heatmap.set_clim(-1,1)
    plt.tight_layout()
    plt.show()
    
visualize_data()

from collections import Counter
import numpy as numpy
import pandas as pandas
import pickle
import sklearn
from sklearn import svm, model_selection as cross_validation, neighbors
from sklearn.ensemble import VotingClassifier, RandomForestClassifier

def process_data_for_labels(ticker):
    hm_days = 7
    df = pandas.read_csv("sp500_joined_closes.csv", index_col=0)
    tickers = df.columns.values.tolist()
    df.fillna(0, inplace=True)

# percentage change for the past seven days; (the day - past seven days) / the day
    for i in range(1, hm_days+1):
         df["{}_{}d".format(ticker, i)] = \
             (df[ticker].shift(-7) - df[ticker]) / df[ticker]

    df["{}_percent_change".format(ticker)] = \
        (df[ticker] - df[ticker].shift(7)) / df[ticker]

    df.fillna(0, inplace=True)
    return tickers, df


def buy_sell_hold(*args):
    columns = [c for c in args]
    requirement = 0.02
    for column in columns:
        if column > 0.025:
            return 1
        if column < -0.025:
            return -1
    return 0


def extract_feature_sets(ticker):
    tickers, df = process_data_for_labels(ticker)

    df["{}_target".format(ticker)] = list(map(buy_sell_hold,
                                                      df["{}_percent_change".format(ticker)]
                                                      #df["{}_1d".format(ticker)],
                                                      #df["{}_2d".format(ticker)],
                                                      #df["{}_3d".format(ticker)],
                                                      #df["{}_4d".format(ticker)],
                                                      #df["{}_5d".format(ticker)],
                                                      #df["{}_6d".format(ticker)],
                                                      #df["{}_7d".format(ticker)]
                                                      ))

    # targets
    values = df["{}_target".format(ticker)]
    str_values = [str(i) for i in values]
    print("Stock:", "{}".format(ticker))
    print("Data spread:", Counter(str_values))

    df.fillna(0, inplace=True)
    df = df.replace([numpy.inf, -numpy.inf], numpy.nan)
    df.dropna(inplace=True)

    df_vals = df[[ticker for ticker in tickers]].pct_change()
    df_vals = df_vals.replace([numpy.inf, -numpy.inf], 0)
    df_vals.fillna(0, inplace=True)

    x = df_vals.values
    y = df["{}_target".format(ticker)].values

    return x, y, df

def do_ml(ticker):
    X, y, df = extract_feature_sets(ticker)
    
    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size = 0.25)
    
    # clf = neighbors.KNeighborsClassifier()
    clf = VotingClassifier([('lsvc', svm.LinearSVC()), 
                            ('knn', neighbors.KNeighborsClassifier()),
                            ('rfor', RandomForestClassifier())])
    
    clf.fit(X_train, y_train)
    confidence = clf.score(X_test, y_test)
    print('Accuracy:',confidence)
    predictions = clf.predict(X_test)
    print('Predicted Spead:', Counter(predictions))
    
    return confidence
do_ml('FB')

